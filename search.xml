<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>短评《现代 C++ 白皮书》</title>
    <url>/comments/2021/12/28/develop-modern-cpp/</url>
    <content><![CDATA[<p>近几天读完了 Bjarne Stroustrup 的 HOPL4 论文 <a href="https://www.stroustrup.com/hopl20main-p5-p-bfc9cd4--final.pdf">Thriving in a Crowded and Changing World: C++ 2006–2020</a> 经由 Boolan 组织翻译的中文版，相关文本内容托管在 GitHub 上，<a href="https://github.com/cpp-club/cxx_hopl4_zh">在线阅读</a>。</p>
<p>不谈其中具体的技术细节，我从 Bjarne 反思 C++ 作为一门编程语言在几十年来如何发展，遇到的问题以及未来的方向的考虑的过程中得到了不少启发，这里做个转述和简短的评论。</p>
<span id="more"></span>

<h2 id="目标与原则"><a href="#目标与原则" class="headerlink" title="目标与原则"></a>目标与原则</h2><p>一门编程语言也好，一个开源项目也好，要想获得长久的生命力，无一不是面向真实的用户问题，形成自己的一套解决方法和原则，并长期坚持予以贯彻。C++ 的发展在 Bjarne 的眼中即是如此。</p>
<p>C++ 作为一门通用编程语言，能够纳入其所要解决的问题涵盖的范围相当广泛。甚至可以说任何需求都可以是 C++ 的需求。在这样的背景下，Bjarne 还是给出了应该避免的错误关注点，指出哪些类型的需求是可疑的。对于一个雄心勃勃的新项目来说，将所有需求都纳入自己的范畴之内无疑是极具诱惑的，但是知道自己不做什么，才是让这个项目脚踏实地真正解决问题的第一步。</p>
<p>Bjarne 总结了 C++ 发展过程当中的教训，包括了一些错误的关注点</p>
<ul>
<li>只为专家服务。某个功能从开始的时候就要满足所有专家的需要。</li>
<li>模仿。我们需要这个功能，因为它在另外某个语言里很流行。</li>
<li>理论性。语言理论里说语言一定要有这个特性。</li>
<li>革命性。此功能非常重要，以至于我们必须打破兼容性，或者摒弃那些不好的老方法。</li>
</ul>
<p>这些都是非常经典的说辞，论文里却对它们全部予以驳斥。Bjarne 观察到用户对 C++ 的要求是</p>
<ul>
<li>让语言更简单！</li>
<li>立即添加这两个必要特性！！</li>
<li>不要搞砸我的（任何）代码！！！</li>
</ul>
<p>这三者其实是相互矛盾的，语言的简化和演进会对兼容性形成挑战，新增特性和简单性之间也会有所冲突。Bjarne 由此归纳出来的发展原则是</p>
<ul>
<li>问题驱动。C++ 开发应该被那些真实世界中的具体问题的需求所驱动。</li>
<li>简单。C++ 应该从简单、高效、易用的解决方案中进行推广而成长。</li>
<li>高效。C++ 语言和标准库应该遵循零开销原则。</li>
<li>稳定性。不要搞砸我的代码！</li>
</ul>
<p>并且几乎总是站在简单性的一边。好的软件通过提供恰如其分的抽象和合理的默认行为来简化用户逻辑的表达。Bjarne 反复提及的设计理念是所谓的“洋葱原则”</p>
<blockquote>
<p>如果要完成的任务是简单的，那就用简单的方法做；当要完成的任务不是那么简单时，就需要更详细、更复杂的技巧或写法。这就好比你剥下了一层洋葱。剥得越深，流泪就越多。</p>
</blockquote>
<p>这个原则也在 Perl 语言的设计思想当中有所体现</p>
<blockquote>
<p>Easy things should be easy, and hard things should be possible.</p>
</blockquote>
<p>往上或许可以追溯到 Alan Kay 的类似观点</p>
<blockquote>
<p>Simple things should be simple, complex things should be possible.</p>
</blockquote>
<p>简单，提供足够的封装，一个软件才能够为用户带来价值。</p>
<p>除此以外，对于 C++ 语言在实现上的原则，Bjarne 贯穿全文的强调了两点</p>
<ul>
<li>语言结构到硬件设备的直接映射</li>
<li>零开销抽象<ul>
<li>你不用的东西，就不需要付出代价。</li>
<li>你使用的东西，手工写的代码也不会更好。</li>
</ul>
</li>
</ul>
<p>这也是 C++ 定位在系统编程语言带来的需求，原文的表达是“不要给 C++ 以下的低级语言留有余地（汇编语言除外）”。</p>
<h2 id="工作组织方式"><a href="#工作组织方式" class="headerlink" title="工作组织方式"></a>工作组织方式</h2><p>原文第三章《C++ 标准委员会》花了一章的篇幅讲述了几十年间推动 C++ 语言演进的组织的架构，以及它是如何发挥作用的。限于短评的篇幅这里不做展开讨论，仅罗列原文总结的 C++ 标准委员会在设计和演进语言时面临的问题，几乎每一个都一针见血。强烈建议阅读原文全文（3.3 节），Bjarne 在各个特性的讨论中间也会以该特性为例子讲述碰到的问题和解决方案。</p>
<ul>
<li>延迟</li>
<li>孤立特性</li>
<li>后来者居上</li>
<li>热情总青睐新事物</li>
<li>过度自信</li>
<li>实现时机不当</li>
<li>特性交互</li>
<li>篇幅和分心</li>
<li>精确规范</li>
<li>经院主义</li>
<li>方向</li>
<li>专一关注</li>
<li>原则的不适当应用</li>
<li>倾向专家的偏见</li>
<li>聪明的问题</li>
<li>不愿妥协</li>
<li>缺乏优先级</li>
<li>完美主义</li>
<li>少数人的阻挠</li>
<li>内聚的团体</li>
</ul>
]]></content>
      <categories>
        <category>tison</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>软件工程</tag>
        <tag>开源共同体</tag>
      </tags>
  </entry>
  <entry>
    <title>Protobuf Gradle Plugin 的用例</title>
    <url>/comments/2022/03/08/gradle-protobuf/</url>
    <content><![CDATA[<p>近日尝试利用 <a href="https://github.com/apache/ratis">Apache Ratis</a> 这个项目包装一个 Raft 协议驱动的状态机，遇到了需要用 Protobuf 传输数据的场景。由于 Gradle 构建工具的门槛和 Java 语言项目的某些惯例碰到了使用上的问题，这里记录一下我在这个玩具项目当中的用例。</p>
<span id="more"></span>

<p>首先介绍一下整个项目的主要目录结构，这里只包含最小复现需要的集合</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">project/</span><br><span class="line">project/proto/</span><br><span class="line">project/proto/RMap.proto</span><br><span class="line">project/build.gradle</span><br><span class="line">project/settings.gradle</span><br></pre></td></tr></table></figure>

<p>其中 <code>settings.gradle</code> 只有一行默认生成的 <code>rootProject.name = &#39;dryad&#39;</code> 信息，<code>RMap.proto</code> 是一个普通的不包含 gRPC 定义的 proto 文件。<code>RMap.proto</code> 文件内容如下</p>
<figure class="highlight protobuf"><table><tr><td class="code"><pre><span class="line">syntax = <span class="string">&quot;proto3&quot;</span>;</span><br><span class="line"><span class="keyword">option</span> java_package = <span class="string">&quot;org.tisonkun.dryad.proto.rmap&quot;</span>;</span><br><span class="line"><span class="keyword">option</span> java_outer_classname = <span class="string">&quot;RMapProtos&quot;</span>;</span><br><span class="line"><span class="keyword">option</span> java_generate_equals_and_hash = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> dryad.rmap;</span><br><span class="line"></span><br><span class="line"><span class="keyword">message </span><span class="title class_">GetRequest</span> &#123;</span><br><span class="line">    <span class="type">bytes</span> key = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">message </span><span class="title class_">GetResponse</span> &#123;</span><br><span class="line">    <span class="type">bool</span> found = <span class="number">1</span>;</span><br><span class="line">    <span class="type">bytes</span> key = <span class="number">2</span>;</span><br><span class="line">    <span class="type">bytes</span> value = <span class="number">3</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">message </span><span class="title class_">PutRequest</span> &#123;</span><br><span class="line">    <span class="type">bytes</span> key = <span class="number">1</span>;</span><br><span class="line">    <span class="type">bytes</span> value = <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">message </span><span class="title class_">PutResponse</span> &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>主要使用 <a href="https://github.com/google/protobuf-gradle-plugin">Protobuf Gradle Plugin</a> 的逻辑都在 <code>build.gradle</code> 文件里，文件内容如下</p>
<figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">plugins &#123;</span><br><span class="line">    id <span class="string">&#x27;java&#x27;</span></span><br><span class="line">    id <span class="string">&#x27;com.google.protobuf&#x27;</span> version <span class="string">&#x27;0.8.18&#x27;</span></span><br><span class="line">    id <span class="string">&#x27;com.github.johnrengelman.shadow&#x27;</span> version <span class="string">&#x27;7.1.2&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">repositories &#123;</span><br><span class="line">    mavenCentral()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">sourceCompatibility = <span class="number">17</span></span><br><span class="line">targetCompatibility = <span class="number">17</span></span><br><span class="line"></span><br><span class="line">dependencies &#123;</span><br><span class="line">    implementation <span class="string">&#x27;com.google.protobuf:protobuf-java:3.19.2&#x27;</span></span><br><span class="line">    implementation <span class="string">&#x27;org.apache.ratis:ratis-thirdparty-misc:0.7.0&#x27;</span></span><br><span class="line"></span><br><span class="line">    protobuf files(<span class="string">&quot;proto/&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">protobuf &#123;</span><br><span class="line">    protoc &#123;</span><br><span class="line">        artifact = <span class="string">&#x27;com.google.protobuf:protoc:3.12.0&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">shadowJar &#123;</span><br><span class="line">    configurations = []</span><br><span class="line">    relocate <span class="string">&#x27;com.google.protobuf&#x27;</span>, <span class="string">&#x27;org.apache.ratis.thirdparty.com.google.protobuf&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>编译和构建工具采用的版本信息如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">------------------------------------------------------------</span><br><span class="line">Gradle 7.4</span><br><span class="line">------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">Build time:   2022-02-08 09:58:38 UTC</span><br><span class="line">Revision:     f0d9291c04b90b59445041eaa75b2ee744162586</span><br><span class="line"></span><br><span class="line">Kotlin:       1.5.31</span><br><span class="line">Groovy:       3.0.9</span><br><span class="line">Ant:          Apache Ant(TM) version 1.10.11 compiled on July 10 2021</span><br><span class="line">JVM:          17.0.2 (Eclipse Adoptium 17.0.2+8)</span><br><span class="line">OS:           Mac OS X 10.15.7 x86_64</span><br></pre></td></tr></table></figure>

<p>这个用例当中有两个注意点。</p>
<p><strong>第一个注意点是 protobuf 的配置方式。</strong></p>
<p>可以看到在 <code>dependencies</code> 配置块中声明了 proto 文件的路径。我不记得是不是有默认的查询路径比如 <code>&lt;project&gt;/src/main/proto</code> 这样的，但是建议还是明确写出来为好，毕竟业界也没有什么公认的标准，每个插件工具的假设不一定采用同一套约定。</p>
<p>另外就是 <code>protobuf</code> 配置块中声明了 <code>protoc</code> 工具的版本。Protobuf Gradle Plugin 的<a href="https://github.com/google/protobuf-gradle-plugin#customizing-protobuf-compilation">官方文档</a>当中还介绍了如何整合 gRPC 等插件等控制 <code>protoc</code> 编译过程的方式。玩具项目当中不需要，因此略过。</p>
<p>最后是 <code>protoc</code> 和 <code>protobuf-java</code> 的版本不一样，如果还要引入 gRPC 的插件和 JAR 包依赖，还会有其他不一样的版本。这是因为 Protobuf 生态并不是整体同步发布的，而是各个组件很大程度上自主开发和发布的缘故。具体的兼容矩阵我没有研究过，但是一般来说锁定了某个版本就不太会轻易升级了。比如 Apache Hadoop 的 Protobuf 版本一直停留在 2.5.0 版本上。印象中 3.0 版本以后的兼容性还是比较好的，3.10+ 版本之间的升级还算顺滑。</p>
<p><strong>第二个注意点是 Gradle Shadow Plugin 插件的使用。</strong></p>
<p><a href="https://imperceptiblethoughts.com/shadow/">Gradle Shadow Plugin</a> 很大程度上是 <a href="https://maven.apache.org/plugins/maven-shade-plugin/">Maven Shade Plugin</a> 的同位替代。也就是说，服务于需要把依赖项一起打成一个大 JAR 包的场景。</p>
<p>通常来说，Maven 或 Gradle 项目打包的时候，依赖项都不会进入到最终产物当中。因为打包就只是对你写的这些代码编译出来的 class 文件打包，而不是像 C &#x2F; Rust 这种产生二进制可执行文件的思路。Java 语言程序运行起来，是需要程序员把所有的依赖项都写进 classpath 里，再指定要运行的类，执行其 Main 方法启动的。这种情况下打包不需要把依赖项都搭进去。</p>
<p>这种方案对于企业自己管理所有依赖，大部分软件是自包含少依赖的大型软件的场景是比较合理的。但是随着互联网的兴起和合作开发效率提升，一个项目依赖大量其他项目的情形越来越多，这些其他项目也有自己的开发周期，往往会产生多个版本的 JAR 包发布产物。这种情况下再要求程序员自己去管理依赖项，管理 classpath 的内容，在生产上就是既繁琐有不可靠的了。</p>
<p>因此，Gradle Shadow Plugin 和 Maven Shade Plugin 解决的问题就是把所有依赖在打包的时候也打进构建产物当中，产生一个 <code>project-all.jar</code> 文件。用户可以直接把这一个 JAR 包加入 classpath 就能保证所有的依赖都已经就绪。甚至在 MANIFEST 文件中写好默认的 MainClass 信息，就能通过 <code>java -jar</code> 命令将大 JAR 包以一种形如二进制可执行文件的方式运行起来。</p>
<p>不过，我们这里用上的不是打一个大 JAR 包的功能，而是在这个大需求下解决 package relocation 问题的功能。</p>
<p>Java 语言程序依靠全限定名来识别一个类，每个 ClassLoader 都对每个全限定名都只会加载一个类实例。如果 classpath 当中存在两个相同全限定名的类，那么根据 ClassLoader 的实现策略，可能会加载其中任意一个，或者报错。</p>
<p>对于服务端应用例如 Apache Flink 和 Apache Ratis 而言，它们自己需要依赖 protobuf 或 akka 等三方库，同时它们自己的用户也有可能依赖这些三方库，那么用户内部逻辑使用的三方库版本，跟用户逻辑需要跟服务端打交道时使用的三方库版本，就有可能在 classpath 当中同时存在。如果这两个版本不兼容，就会出现运行时错误。</p>
<p>由于服务端应用往往受众更广，通常来说解决方案是用户应用程序采用跟服务端相同的依赖版本。但是如果用户不是直接依赖跟服务端可能冲突的三方库，而是间接依赖，那么这个版本对齐的工作往往就很难做了。</p>
<p>另一种形式是形如 akka 生态当中的 play 框架，直接暴露操作 akka 底层数据结构的接口，用户自己不依赖 akka 而是通过 play 提供的接口使用 akka 的能力。但是这种形式只对 akka 和 play 这样由同一个团队开发的软件是比较合适的，放在更加复杂的开源软件生态当中就很难配合了。</p>
<p>因此从服务端的角度出发，为了避免用户遇到这一难题，一个彻底的解决方法就是 package relocation 更改自己依赖的三方库的全限定名。</p>
<p>比如上面 <code>build.gradle</code> 里配置项显示的</p>
<figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">shadowJar &#123;</span><br><span class="line">    configurations = []</span><br><span class="line">    relocate <span class="string">&#x27;com.google.protobuf&#x27;</span>, <span class="string">&#x27;org.apache.ratis.thirdparty.com.google.protobuf&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这意味着把所有 <code>com.google.protobuf</code> 的文本都替换成 <code>org.apache.ratis.thirdparty.com.google.protobuf</code> 的字样，也包括字符串当中的情况，以应对动态加载的用例。</p>
<p>这样，服务端最终打出来的 JAR 包里，使用的类全限定名就不是 <code>com.google.protobuf.Message</code> 而是 <code>org.apache.ratis.thirdparty.com.google.protobuf.Message</code> 了，这也就跟用户依赖的 <code>com.google.protobuf.Message</code> 不同，从而不会起冲突。</p>
<p>当然，这种 package relocation 不仅仅在服务端的使用上会改掉全限定名，也需要类的实现本身也是以新的全限定名来提供的。因此 Apache Ratis 项目提供了 <a href="https://github.com/apache/ratis-thirdparty"><code>ratis-thirdparty-misc</code></a> 库，Apache Flink 项目提供了 <a href="https://github.com/apache/flink-shaded"><code>flink-shaded</code></a> 库。其中的内容就是把服务端依赖的软件以 relocate 之后的名称重新发布。</p>
<p>对于这个玩具项目来说，它需要的是保持跟 Apache Ratis 服务端一样的 protobuf 依赖的全限定名，保证能够嵌入到 Apache Ratis 的服务端实现当中。对于其中的 proto 定义部分，它并不需要真的把依赖项也打进自己的 JAR 包里，这个打大 JAR 包的工作会交给最终的 dist package 完成。所以我们还需要把 Gradle Shadow Plugin 默认打入所有运行时依赖的行为变掉。这就是 <code>configurations = []</code> 一行起的作用，把打入最终 JAR 包的依赖项置空，这样就只会包含 proto 文件编译出来的 class 文件了。这样的用例，其实与 Maven Shade Plugin 的惯用法有较大的差别，更像是 <a href="https://code.google.com/archive/p/maven-replacer-plugin/">Maven Replacer Plugin</a> 的用法。</p>
<p>最后作为小 tip 值得一提的是，上面提到 package relocation “也包括字符串当中的情况，以应对动态加载的用例”。这其实导致了 akka 项目很难利用常规的 package relocation 插件来完成这个工作。惯例上，Java 语言项目的全限定名以域名开头，形如 <code>com.google.protobuf</code> 或 <code>org.apache.ratis</code> 等等。一般而言这种形式的字符串只会出现在类的全限定名当中。然而，akka 作为一个 Scala 项目采用了 <code>akka.actor</code> 形式的全限定名前缀。不幸的是，这种前缀模式跟 akka 的配置项是重叠的。这就导致 package relocation 会同时改变配置项的名称。这其实不是我们想要的，因为这样用户也要跟着改配置项的名称才能跟 relocate 之后的 akka 库交互，这通常来说是非常难做到并且与大部分开发者的直觉和生态项目的假设是冲突的。</p>
]]></content>
      <categories>
        <category>tison</category>
      </categories>
      <tags>
        <tag>Gradle</tag>
        <tag>Java</tag>
        <tag>Protobuf</tag>
      </tags>
  </entry>
  <entry>
    <title>为啥 Paxos 这么难？</title>
    <url>/comments/2022/03/08/paxos-hard/</url>
    <content><![CDATA[<p>本文中，我将<strong>忽略性能等实际问题</strong>，主要聊点 general 的东西，如基本概念、表达力，或者说“怎么把它变为可能”，而不是“怎么把它搞得快的飞起”。另外，我会尽量写的让不了解分布式系统或共识的读者也能看懂。不过，如果你已经对 Raft 或 Paxos 之类的共识算法有了概念，那当然还是更好。</p>
<span id="more"></span>

<h2 id="我学习共识的经历"><a href="#我学习共识的经历" class="headerlink" title="我学习共识的经历"></a>我学习共识的经历</h2><p><a href="https://www.zhihu.com/question/65038346/answer/227674428">这个知乎回答：有没有哪一刻让你感受到了文献作者的恶意？</a>是我第一次听说 Paxos 和共识。当时看了感觉贼逗，同时也就在脑子里留下了 “Paxos 很难” 的初印象。</p>
<p>正好一年前，我在写 MIT 6.824 的 Raft lab。读 Raft 的时候我感觉它挺好懂的，把东西拆成了模块，把每个模块解释得都很清楚。里面还有一章 “What’s wrong with Paxos?” ，我读的时候又情不自禁地乐了起来。总之，虽然我在 debug 的时候还是有点小困难的，但学 Raft 的认知过程算是很平滑。</p>
<p>上学期，我有个作业要实现 Paxos。我碰巧收藏过<a href="https://blog.openacid.com/algo/paxos/">这个博客</a>，就拿出来看看。它用很简单的方式解释了 Paxos，我也就按照它讲的实现了（basic）Paxos，没再看论文或者别的文章。作业还要求我们用一个特定的方案实现 multiple decisions，所以我也没看 multi-Paxos 之类的东西。</p>
<p>上学期我还上了 Concurrent Algorithms 和 Distributed Algorithms 两门课。它们都比较理论，都讲了共识，我学的时候感觉共识这东西挺简单的。DA 课上的共识算法很像 Paxos，而且简单到一张 slide 就够了。另外 CA 课上的 Universal Construction 以及 DA 课上的 Total Order Broadcast 算法，这两个东西可以说证明了共识基本上可以用来做任何事情，而且这两个算法也不难理解。然后我就开始想，为什么人们会觉得 Paxos 难理解，这也是我想写这篇博客的原因。</p>
<p>最后，我读了 Paxos 的两篇论文，确认了它们真的都挺好懂的。但 Lamport 的语言太有意思了。<em>The Part-Time Parliament</em> 讲的特别详细又很直白，就是仿佛把名词术语做了一下简单的映射。<em>Paxos Made Simple</em> 则是用平实的语言谈直觉理解，它倒是有点像一篇博客。</p>
<p>话不多说，我们还是进入正题吧。</p>
<h2 id="各种抽象：Consensus-Replicated-Log-和-Replicated-State-Machine"><a href="#各种抽象：Consensus-Replicated-Log-和-Replicated-State-Machine" class="headerlink" title="各种抽象：Consensus, Replicated Log 和 Replicated State Machine"></a>各种抽象：Consensus, Replicated Log 和 Replicated State Machine</h2><p>首先，让我们先不管具体的共识算法，先来看看它的抽象（或接口）是怎么回事。</p>
<p>在分布式系统中，我们通常想要 <em>share</em> 东西。那么 shared objects 或叫 shared data structures 就很有用。它就像单机数据结构一样（像 queue, map），但可以被不同的机器（或线程）访问。也可以说是多台机器共同维护一个全局对象，每台机器复制了全局对象的状态。</p>
<p>Replicated state machine 可以说是最强的抽象了，算是所有 shared data structures 的推广。(或者也可以说 shared data structures 都可以用 replicated state machine 来实现）。你可能很容易想到，维护一个 replicated log 就是一种实现 replicated state machine 的自然的方法。完全没错。</p>
<p>顺便一提，replicated log 也可以等价成另一个抽象 total order broadcast：每个机器广播消息，保证所有人以相同的全局顺序收到消息。(很像，不过无所谓，不是很重要。）</p>
<p>那么什么是共识呢？最原始的 consensus 的定义来了。首先，它也就是一个 shared objects。它的 <em>sequential specification</em>（如果它被不同的机器按顺序访问（好比加了锁），怎么工作）是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">维护一个变量：prop</span><br><span class="line">初始值: ⊥ (未初始化)</span><br><span class="line"></span><br><span class="line">propose(v):</span><br><span class="line">    if prop == ⊥:</span><br><span class="line">        prop = v</span><br><span class="line">    return prop</span><br></pre></td></tr></table></figure>

<p>是不是很简单？有几个注意点：</p>
<ul>
<li>它是一次性的，single decision。它可以被看作是一个 write-once variable。</li>
<li>这里用了同步风格的接口，用基于事件的异步接口也行。</li>
<li>通常假设每个机器都有东西要 propose，而 propose 是获得最终的 decision 值的唯一途径。我认为这种约定俗成只是为了简单起见。你可以很容易地修改接口，改成不用 propose 也能知道值，就像 Paxos 里分了 proposer, acceptor 和 learner，本质上其实一样，不太重要。</li>
</ul>
<p>我们也可以等价地通过给出它的性质来描述 consensus：</p>
<ul>
<li>Validity: A decided value is proposed.</li>
<li>Agreement: No processes decide differently.</li>
<li>Termination: Every process eventually decides.</li>
</ul>
<h2 id="用-Consensus-实现-Replicated-State-Machine"><a href="#用-Consensus-实现-Replicated-State-Machine" class="headerlink" title="用 Consensus 实现 Replicated State Machine"></a>用 Consensus 实现 Replicated State Machine</h2><p>Consensus 是一个如此简单的抽象，但它足够强大，可以实现 replicated state machine，也就是说，它可以用来实现任何 shared object。这个结论有一个响亮的名字: <strong>Universality of Consensus</strong>。</p>
<p>首先我们可以考虑一个 naïve 的方案：consensus 已经算是个单条 replicated log entry 了，那为什么不直接用一个 consensus list 作为 replicate log 呢？当一台机器要 append entry 的时候，它就一直向前 propose，直到它的 proposal 在一个 consensus instance 中被 decide。</p>
<p>这个想法基本上差不多可行了，除了一个关键问题：可能会有人一直 propose 赢不了，也就是会 starve。解决方案也不是很复杂：现在，每个人不仅 propose 自己的请求，而且还<strong>帮助</strong>别人。具体来说，当一个新的想要 append 的 entry 出现时，先把它广播出去（同时每个人一直在收集别人的请求）。然后，每次 propose <strong>所有收集到的 pending entries</strong>（而不是一条 entry）。这就成了!</p>
<p>当然，这不是唯一的方法，而且没啥优化，不过完全 work！</p>
<p>其实在看这个算法之前你可能就觉得这个事儿肯定是能做到的。我就是展示了有一个简单的方法，让我们相信确实可以做到。我觉得从 consensus 到 replicated log 就好像从手动档切换到自动档。</p>
<h2 id="为啥-Paxos-这么难？"><a href="#为啥-Paxos-这么难？" class="headerlink" title="为啥 Paxos 这么难？"></a>为啥 Paxos 这么难？</h2><p>如果你知道 Paxos 的工作原理，你可能已经发现它的核心算法就是实现了共识。许多复杂度来自于把它变成 replicated log。在论文中似乎没有明确说明这个关系（虽然我没细读这部分）。但是，脑子里带着上文的算法和关于 consensus 的知识，并忽略各种实现细节、性能问题（尽管这在工程师的思维中可能很难），你就可以说服自己，它确实 work，而且很简单。All you need is (single-decision) consensus! 换句话说，如果你已经知道了 consensus 这个抽象，然后想找一个实现，你立刻就能搞懂 Paxos 在干嘛。所以，复杂的不是 Paxos 算法本身，而是有很多概念混在一起没搞清楚。</p>
<p>还不了解 Paxos 的读者，可以回去读一读这篇论文，现在可以只关注 single decision 的部分了，不用头疼 multiple decision！不过我还是在这里简单地解释一下 Paxos。</p>
<p><a href="https://blog.openacid.com/algo/paxos/">之前提到的 xp 的博客</a>很清晰易懂，因为它也是主要专注讲了简单的东西，没有讲的太多把读者搞晕。但我认为这篇博客中的想法可以再进一步概括一下。</p>
<p>首先，slide 1-5 相当于是引入我们需要 (single-decision) consensus 这个抽象。然后讨论了许多失败的尝试（但都还挺重要的技术）。</p>
<ul>
<li>slide 6-9: Single writer <em>all-ack</em>. 不允许任何 crash。</li>
<li>slide 10-12: Single writer majority-ack（或者叫 <em>majority-write</em>）。为了让这个方法 work，<em>Timestamp</em> 和 <em>majority-read</em> 也同时需要。这个算法不允许 writer crash。</li>
<li>slide 14-17: Majority-write 也不能推广到 <strong>multiple writers</strong>.</li>
<li>slide 18-19: (majority) Read before (majority) write.</li>
<li>slide 20: Request (majority) promise before (majority) write.</li>
</ul>
<p>没错，我认为 Paxos 的思想可以概括为一句话：<strong>request promise before write</strong>！它就是这么简单，不到 200 行代码就够实现了。</p>
<p>xp 以一种简单的方式告诉你 Paxos 是<em>如何</em>工作的，但你可能仍然想知道<em>为什么</em>我们要这么干，以及这么干是不是真的稳了。现在我应该说，在 Paxos 论文中，Lamport 是（从他想保证的性质中）<strong>推导</strong>出了这个想法。因此，如果你在已经了解了 Paxos 之后再重新阅读这篇论文，你可能就会发现它相当容易理解，而且有很精彩的推理和直觉。但也许恐怕这也是很多人一开始没能理解的原因，因为他们不习惯这种思维方式，在推导为什么 work 之前，就是想先知道它到底是具体怎么 work 的。</p>
<p>顺便一提，xp 的后续博客<a href="https://drmingdrmer.github.io/algo/2020/10/28/paxoskv.html">用200行代码实现基于paxos的kv存储</a>实现了（single-decision）Paxos，然后手动管理 consensus instance。（还有一个更复杂的后续博客在<a href="https://blog.openacid.com/algo/mmp3/">这里</a>。）所以你也可以通过看这个实现来学习（single-decision）Paxos。</p>
<h2 id="Raft-更简单吗？"><a href="#Raft-更简单吗？" class="headerlink" title="Raft 更简单吗？"></a>Raft 更简单吗？</h2><p>让我们回头再看一下Raft。首先，”What’s wrong with Paxos?” 部分。</p>
<blockquote>
<p>We hypothesize that Paxos’ opaqueness derives from its choice of the single-decree subset as its foundation. Single-decree Paxos is dense and subtle: it is divided into two stages that do not have simple intuitive explanations and cannot be understood independently.</p>
</blockquote>
<p>我现在觉得这个评价有点 <strong>unfair</strong>。Single-decision consensus 是分布式计算理论中一个成熟的抽象。Single-decree Paxos 也有很好的直觉在里面。</p>
<hr>
<p>另一个评价是，Paxos 没有为在 <em>real-world</em> systems 中建立 <em>practical</em> 的实现提供良好的基础，这可能确实。然而，我认为这对 Paxos 来说根本就是个 <strong>non-goal</strong>。它就是在讲解决一个理论问题的一种优雅的算法。它就根本<strong>不太关心</strong>你在现实世界中如何实现它……我认为 Lamport 也是一个比较偏理论的 researcher。(他建立了分布式计算理论的基础。）现实世界的东东对 theory researchers 可能没有那么大的吸引力，如果问题在理论上没啥意思的话……</p>
<hr>
<p>现在让我们来看看 Raft 本身。我也将尝试用几句话来描述它。</p>
<p>首先，它谈了 replicated state machine，并且<strong>明确地告诉你我们正在造 replicated log</strong>。工程师可能对 consensus 不熟悉，但对 log 一定非常了解。</p>
<p>第二，Raft 选择了 <strong>leader-based</strong> 方法：只有 leader 可以与外界交互以及 append entry。Paxos 则完全是 <strong>peer-to-peer</strong>。有一个 leader 通常会使主要流程或 “happy path” 更容易理解。Raft 自然地选择了 majority-write。那么唯一的问题是如何处理 leader crash。Raft 的方法是：限制节点不给 outdated 节点投票。这个技术很简单，但也需要花些功夫去理解它为什么 work，因为其实里面涵盖了很多 edge cases。要维护的性质其实是，新的 leader 必须<em>至少</em>包含所有 majority-written entries，但是否包含更多的 pending entries 则无所谓。</p>
<p>最后，replicated log 里会存在不一致的状态，leader 通过把它覆盖掉来修复。</p>
<p>所以 Raft 简单吗？它的核心思想也不难。它也就是 single-leader majority-write …… 再加上一些额外但也很简单的 trick（以确保 majority-write 能 work）。</p>
<p>简而言之，Raft</p>
<ul>
<li>直接实现 replicated log。</li>
<li>谈论<strong>具体的概念</strong>，如 heartbeat, timeout, RPC and crash recovery，而不是像 theory researcher 一样谈论抽象概念。</li>
<li>谈论所有路径中的<strong>所有细节</strong>（状态转换），并且算是用一种 manageable way <strong>暴露了复杂度</strong>。(Paxos 不关心这些 <strong>trivil</strong> 的实现复杂度)。</li>
</ul>
<p>所以读完 Raft 后，你基本上可以直接<strong>翻译成代码</strong>。相对的，Paxos 在理论上很简单，读完后，你可能会思考一阵子，然后大叫一声：<strong>哦，它确实 work! 太简单了！</strong>（就像一个数学家一样。）那也就难怪大多数人，尤其是工程师，会觉得 Raft 读起来更舒服。</p>
<h2 id="更多关于-Consensus-的话题"><a href="#更多关于-Consensus-的话题" class="headerlink" title="更多关于 Consensus 的话题"></a>更多关于 Consensus 的话题</h2><p>关于 consensus，还有更多有趣的理论问题。除了 universality 之外，最重要的问题可能是共识的 <strong>impossibility</strong>！具体来说，FLP impossibility 说：在一个异步的分布式系统中，如果可能有一个进程 crash，共识是不可能实现的。</p>
<p>啊？那 Paxos 和 Raft 在干嘛？</p>
<p><em>Don’t panic.</em> 这里的<strong>异步</strong>系统是指：每个进程可以被 delay <em>任意长</em>的时间，而我们对别人是否活着一无所知。但在实践中，我们其实有一些（关于<strong>时间</strong>的）假设。现实世界更像是一个<strong>最终同步的</strong>（eventually synchronous）系统，这意味着我们可以有一个 eventually perfect failure detector：它可能会误诊把活人当死人，但是如果再多等等，它会自己改正错误的结论。其实 heartbeat 和 timeout 机制基本上就是在实现一个 eventually perfect failure detector。</p>
<p>另一个附带说明是，实际上，我们在上面假设了通过 message-passing 进行通信。如果我们切换到 shared memory，我们仍然会有 FLP impossibility。准确地说，只使用 <strong>shared registers</strong> 是不可能实现共识的。</p>
<p>其实 FLP impossibility 的证明也非常精彩。其核心思想是：首先，任何共识算法的执行都必须有一个<strong>临界时间点</strong>（critical timing）。从上帝视角看，整个系统当前并没有达成 decision，但立刻即将（在任何人执行一小步以后）达成 decision。所有后来的步骤都只是在走流程告知所有人结果罢了。(如果你懂命运石之门的话，这意思就是世界线马上要收束了）。然后我们断言，所有人的下一步都想访问同一个 shared register！</p>
<p>为了方便继续讨论，让我们假设我们有两个进程 <code>p1</code> 和 <code>p2</code>。如果他们不访问同一个对象，以下两种 possible histories 是等价的。</p>
<ol>
<li><code>p1</code> 走一步，然后 <code>p2</code> 走一步。</li>
<li><code>p2</code> 走一步，然后 <code>p1</code> 走一步。</li>
</ol>
<p>这说明这个 timing 不 critical 啊，矛盾！</p>
<p>现在假设他们都要访问 shared register <code>x</code>。</p>
<ul>
<li><p>Case 1：如果第一步是要读 <code>x</code>，我们在它读完以后马上把它干掉。那么另一个进程会认为一切都和原来一样啊，所以它做不出 decision！这意味着在 critical timing 必须对整个系统做出一些 <strong>observable change</strong> 才行。所以</p>
</li>
<li><p>Case 2：两个进程的第一步都是写 <code>x</code>。那么以下两种 possible histories 是等价的：</p>
<ol>
<li><code>p1</code> 写 <code>v1</code> 进 <code>x</code>，然后立刻被干掉。<code>p2</code> 将 <code>v2</code> 写入 <code>x</code>。</li>
<li><code>p1</code> 立刻被干掉。<code>p2</code> 将 <code>v2</code> 写入 <code>x</code>。</li>
</ol>
<p>同样，这与 critical timing 相矛盾！（谁先走不重要啊）</p>
</li>
</ul>
<p>这就证完了！(我证了世界线收敛不了。)是不是也很简单？现在你可能也对为什么 impossiblity 能成立也有了点感觉。因为异步是一个太弱的假设。换句话说，它给了 <em>scheduler</em>（或者我们这些证定理的坏人）太大的权力。</p>
<p>更 exciting 的是，上述证明框架适用于更多情况。实际上，我们在上面证明了<em>2个进程</em>之间的共识只使用 register 是不可能的。我们同样可以证明<em>3个进程</em>之间的共识只用 register 和 queue 或 fetch-and-add 是不可能的！但是我们可以用 compare-and-swap 在任何数量的进程之间实现共识！</p>
<p>这些结论给了我们一种<strong>比较 shared objects 的表达力的方法</strong>：consensus number。Register 的 consensus number 为 1，queue 和 FAA 的为 2，CAS 的为 ∞。关于 consensus number 还有一些未解决的研究问题，但我想我们现在还是适可而止吧！</p>
<p>最后总结一句，分布式计算理论还是挺有趣的，值得学习一点。😄</p>
]]></content>
      <categories>
        <category>xxchan</category>
      </categories>
      <tags>
        <tag>分布式共识</tag>
        <tag>分布式系统</tag>
      </tags>
  </entry>
  <entry>
    <title>如何在开源项目中做重构？</title>
    <url>/comments/2022/03/08/refactor-in-open-source-project/</url>
    <content><![CDATA[<p>最近完成了 <a href="https://github.com/datafuselabs/databend/">Databend</a> 存储模块的大重构，在不阻塞现有功能开发的前提下，基本无痛的完成了功能的实现。本文总结了我个人的一些经验，期望能够带来一些启发。</p>
<span id="more"></span>

<hr>
<p>做重构不易，尤其是在一个相当活跃的 codebase 上。Databend 现在每周有 40+ PR 被 merge，在过去的一周中有 800+ 文件发生了变更，代码增加了 21K  行，删除了 12K 行。在这样的代码库上，毕全功于一役的代价是高到可怕的。所以在整个重构的生命周期中，我们都需要跟社区保持密切沟通，让社区知道你想做什么，怎么做，现在的进展如何。在这一次的重构中我总结出了如下经验：</p>
<h2 id="撰写提案"><a href="#撰写提案" class="headerlink" title="撰写提案"></a>撰写提案</h2><p>正如 The Apache Way 所说：<code>Community over code</code>。一个好的开源项目不仅仅是由代码组成，抛开开源共同体谈抽象的技术和代码是没有意义的。因此向开源项目提交大型的变更之前，我们必须要阐述清楚自己的想法，解释动机，让开源共同体知道自己想做什么，想怎么做。</p>
<p>这些落到纸面上的文档在讨论时能够补充信息，完善想法，构建出更好的设计。从长期角度看，文档能够帮助后来者理解当时为什么要提出这样的设计，从而避免重复踩坑。不仅如此，一份好的设计文档往往还能够影响、启发其他开源项目的设计，从而促进整个行业进步。</p>
<p><a href="https://github.com/tisonkun/">@tison</a> 在 <a href="https://zhuanlan.zhihu.com/p/93334196">如何参与 Apache 项目社区</a> 提到过：</p>
<blockquote>
<p>对于任何 non-trivial 的改动，都需要有一定的描述来表明动机；对于大的改动，更需要设计文档来留存记忆。人的记忆不是永久的，总会忘记最初的时候自己为什么做某一件事情，设计文档的沉淀对于社区摆脱人的不确定性演化有至关重要的作用。</p>
</blockquote>
<p>在本次重构之前，我在 Databend 的 <a href="https://github.com/datafuselabs/databend/discussions">Discussions</a> 中向全体社区成员公开地阐述了自己的愿景和希望: <a href="https://github.com/datafuselabs/databend/discussions/3662">proposal: Vision of Databend DAL</a>。然后跟多位相关的模块的维护者取得了沟通，达成了广泛的一致意见，之后才开始了本次的重构。我认为跟维护者取得一致是非常关键的步骤，否则极有可能出现工作到一半时维护者发现想法冲突导致工作被终止或者重来，这是非常沮丧的。</p>
<p>此外，开源共同体本质上都在奉行<strong>基于开源贡献</strong>的精英主义原则。贡献者必须要通过贡献来证明自己的价值，取得社区的信任，然后才能推行自己的主张。所以在提出一个大型改动之前，最好先通过参与一些 good first issue 加入到社区中来，了解社区的规范，熟悉社区的编译流程，跟模块的维护者保持联系，建立自己在社区中的影响力。在本次重构之前，我帮助 Databend 社区完成了新的社区官网上线，改造了全新的 CI Pipeline，跟各个模块的维护者基本都刷了个脸熟。</p>
<p>值得注意的是，Databend 像很多新生的开源项目一样，还没有完善的提案流程，但是这并不意味着我们就不能或者不需要提交提案。提交 Proposal 的意义就在于跟社区沟通达成一致，不要被形式所束缚，只要能最终达成一致就是可以接受的。与此同时，开源项目的治理流程本身也在不断完善和演进。事实上，绝大多数项目中正式的提案处理流程正是在社区在不断的接受和处理一份份提案的过程中被搭建起来的。</p>
<h2 id="创建-Tracking-Issue"><a href="#创建-Tracking-Issue" class="headerlink" title="创建 Tracking Issue"></a>创建 Tracking Issue</h2><p>在提交了 Proposal 通过之后，最好能创建一个 Tracking Issues 来跟踪 Proposal 的实现情况。</p>
<p>通常我们会命名成 <code>Tracking Issue for Xxxx</code>，在这个 Issue 中，我们需要</p>
<ul>
<li>链接到之前通过的 Proposal 以便于社区成员了解当前工作的上下文</li>
<li>列出自己的工作计划和 TODO List</li>
<li>随进度更新自己的进展</li>
</ul>
<p>除了自己的规划安排之外，还有一种比较常见的情况是在 PR review 时维护者经常会提出一些后续的改进建议，我们可以统一汇总到 Tracking Issue 中来。</p>
<p>Tracking Issues 的意义在于让社区了解当前的进展并在适时的时候提供需要的帮助，社区通过查看 Tracking Issue 就能了解 Proposal 目前是处于活跃开发还是停滞状态，对 Proposal 实现感兴趣的成员也能够通过 Tracking Issue 反馈自己的想法和参与意愿。</p>
<p>在本次重构中，我通过 <a href="https://github.com/datafuselabs/databend/issues/3677">Tracking issue for Vision of Databend DAL</a> 来跟踪 Proposal 的进展情况。除了自己的规划的特性之外，我还记录了很多维护者 review 时提供的反馈意见和一些长期的不成熟想法，这些都是未来项目可以改进的方向。</p>
<h2 id="拆分-Pull-Requests"><a href="#拆分-Pull-Requests" class="headerlink" title="拆分 Pull Requests"></a>拆分 Pull Requests</h2><p>在实现 Proposal 的时候要根据实际的情况拆分 PR。</p>
<p>PR 拆的太细会给维护者带来额外的负担，由此产生的大量无用 CI 任务也不利于低碳环保；PR 太大则会导致维护者难以 review，要么草草通过了事，要么迟迟没人 review，这都不利于工作的推进，更不必说大 PR 有更大的概率出现代码冲突。</p>
<p>每个 PR 应当是一个完整的个体，可以实现某个特定的目标。以我的两个 PR 为例：</p>
<ul>
<li><a href="https://github.com/datafuselabs/databend/pull/4001">dal2: Eliminate type parameters in DAL</a>： 消除 DAL 中的类型参数</li>
<li><a href="https://github.com/datafuselabs/databend/pull/4067">dal2: Implement DAL Layer support</a>： 实现 DAL Layer 支持</li>
</ul>
<p>这里的每个 PR 都只做了一件很明确的事情，维护者通过阅读 PR 的标题和描述就能迅速理解这个 PR 在做什么，这样代码 review 的时候就会事半功倍。</p>
<p>PR 的拆分更多依赖于个人的经验和风格，当怎么拆分比较好时，可以请维护者帮忙出主意。</p>
<h2 id="保持专注"><a href="#保持专注" class="headerlink" title="保持专注"></a>保持专注</h2><p>在实现 Proposal 的过程中需要保持专注，不要无限制地延拓工作边界。</p>
<p>实现过程中往往会遇到一些新的待解决问题，又往往与当前的 Proposal 相关联，此时最好采用最小化的原则，优先保证当前的 Proposal 能够成功交付。一方面，人的能力是有极限的，不能因为当前负责实现这个 proposal，就去承担所有相关的任务，这往往会导致相关模块的任务都阻塞在自己身上，没有最大化地利用来自开源共同体的力量；另一方面，望山跑死马，无限制地拓展工作边界会导致自己的成果没有一个清晰的交付时间点，自己会感到精力在不断被耗尽，社区的耐心和期待也在不断地被消磨。</p>
<p>所以我们需要保持专注，努力抗拒新功能和新特性的诱惑，优先保证当前的 proposal 中承诺的功能交付。等到 proposal 完全实现并合并之后，给自己放一个小假，然后再开启新的 proposal 并实现，如此循环。有交付才有激励，才有动力去完成更多的工作，不要设定一个永远无法企及的目标。</p>
<h2 id="寻求帮助"><a href="#寻求帮助" class="headerlink" title="寻求帮助"></a>寻求帮助</h2><p>在实现 Proposal 的过程中，要积极地跟社区交流，向社区寻求帮助。</p>
<p>时刻牢记我们不是一个人在战斗，我们背后是整个开源社区。遇到问题的时候不要一个人闷头苦想，积极的向社区寻求帮助，小到语言特性(尤其是你在使用 Rust 时)，大到功能模块。一个问题查了一天资料也没有结果，问问维护者往往能给出更合理的解决方案或者可行的 work around。</p>
<p>不用担心暴露自己的不足，大家都是这么过来的。开源共同体中的成员往往利益趋向于一致，所以维护者有意愿有动力来帮助解决问题。我最喜欢的 Rust 开发者 <a href="https://github.com/dtolnay">dtolnay</a> 就是一个极为优秀的典范：在 PR <a href="https://github.com/rust-lang/rust/pull/92338">Add try_reserve and try_reserve_exact for OsString</a> 中，dtolnay 给出了细致而明确的 review 意见，帮助我理解了这部分逻辑的细节。</p>
<p>在实现 <a href="https://github.com/datafuselabs/databend/pull/4081">query: Replace dal with dal2, let’s rock!</a> 的过程中，我遇到了一个想了很久也没有想明白的问题，于是提交了<a href="https://github.com/datafuselabs/databend/pull/4081#issuecomment-1034590367">评论</a> 向维护者 <a href="https://github.com/dantengsky">@dantengsky</a> 寻求帮助。在评论中，我给出了问题的描述，完整的 backtrace，还有最简化的复现步骤。在 <a href="https://github.com/dantengsky">@dantengsky</a> 的帮助下，这个问题很快就得到了解决。</p>
<p>阅读 <a href="https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way/blob/main/README-zh_CN.md">提问的智慧</a> 会很有帮助，但是完全没读过也没关系，核心的要旨是互相尊重。不要颐指气使，也不要低声下气。我们尊重维护者是因为他们过往的贡献而非如今的社区地位，相比于大佬之类的无意义恭维，在解决问题后的一声 Thanks 往往更让人感到开心。</p>
<hr>
<p>总得来说，在开源项目中做大规模的重构，最重要的就是保持交流，持续沟通。撰写 Proposal，创建 Tracking Issue，拆分 PRs 都是为了交流服务的。再此基础上，我们需要注意一些实现中的技巧，保持专注，并适时地向社区寻求帮助。以上就是我在本次重构中总结出来的一些经验，希望能够帮助到你，欢迎在评论区一同交流~</p>
]]></content>
      <categories>
        <category>xuanwo</category>
      </categories>
      <tags>
        <tag>开源</tag>
      </tags>
  </entry>
  <entry>
    <title>Rust Enum Layout 的优化</title>
    <url>/comments/2022/01/23/rust-enum-layout/</url>
    <content><![CDATA[<p>今天学到了一点关于 Rust Enum 的冷知识，在开始阅读之前，大家可以猜一下下面的 Rust 代码在常见的 64 bit 机器上的输出是什么？</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">A</span> (<span class="type">i64</span>, <span class="type">i8</span>);</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">B</span> (<span class="type">i64</span>, <span class="type">i8</span>, <span class="type">bool</span>);</span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    dbg!(std::mem::size_of::&lt;A&gt;());</span><br><span class="line">    dbg!(std::mem::size_of::&lt;<span class="type">Option</span>&lt;A&gt;&gt;());</span><br><span class="line">    dbg!(std::mem::size_of::&lt;B&gt;());</span><br><span class="line">    dbg!(std::mem::size_of::&lt;<span class="type">Option</span>&lt;B&gt;&gt;());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在这个 <a href="https://play.rust-lang.org/?version=nightly&mode=release&edition=2021&gist=bab644e35609b5475978821378d3560f">Rust Playground</a> 里可以看到结果。</p>
<span id="more"></span>

<hr>
<p>Rust enum 本质是一种 <a href="https://en.wikipedia.org/wiki/Tagged_union">tagged union</a>，对应代数数据类型中的 sum type，这里不过多展开。在 Rust enum 的实现中，通常用一个 byte 来存储 type tag（大部分 enum 不会超过 256 种类型，更多地会相应扩展），也就是说，理想情况下，以下两个结构体是等价的：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">Attr</span> &#123;</span><br><span class="line">    <span class="title function_ invoke__">Color</span>(<span class="type">u8</span>, <span class="type">u8</span>, <span class="type">u8</span>),</span><br><span class="line">    <span class="title function_ invoke__">Shape</span>(<span class="type">u16</span>, <span class="type">u16</span>),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Color</span> &#123;</span> <span class="type">uint8_t</span> r, g, b &#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Shape</span> &#123;</span> <span class="type">uint16_t</span> w, h &#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Attr</span> &#123;</span></span><br><span class="line">    <span class="type">uint8_t</span> tag;</span><br><span class="line">    <span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">        Color color;</span><br><span class="line">        Shape shape;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在这个实现下，enum 在很多场景下并不是 zero overhead 的。幸运的是，Rust 从未定义过 ABI，而带有数据的 enum 甚至是无法被 <code>repr(C)</code> 表示的，这给了 Rust 充分的空间对 enum memory layout 进行细粒度的优化。这篇文章会涉及一些在 <code>rustc 1.60.0-nightly</code> 下相关优化的介绍。</p>
<p>在开始具体的探索之前，我们需要准备一个辅助函数，来帮我我们查看变量的内存结构：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">print_memory</span>&lt;T&gt;(v: &amp;T) &#123;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;:?&#125;&quot;</span>, <span class="keyword">unsafe</span> &#123;</span><br><span class="line">        core::slice::<span class="title function_ invoke__">from_raw_parts</span>(v <span class="keyword">as</span> *<span class="keyword">const</span> _ <span class="keyword">as</span> *<span class="keyword">const</span> <span class="type">u8</span>, std::mem::<span class="title function_ invoke__">size_of_val</span>(v))</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>以上面的 <code>Attr</code> 为例：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;Attr::<span class="title function_ invoke__">Color</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>));</span><br><span class="line"><span class="comment">// [0, 1, 2, 3, 0, 0]</span></span><br><span class="line"><span class="comment">//  ^  ^  ^  ^  ^^^^</span></span><br><span class="line"><span class="comment">//  |  |  |  |    |</span></span><br><span class="line"><span class="comment">//  |  |  |  |    --- padding</span></span><br><span class="line"><span class="comment">//  |  |  |  -------- b</span></span><br><span class="line"><span class="comment">//  |  |  |---------- g</span></span><br><span class="line"><span class="comment">//  |  |------------- r</span></span><br><span class="line"><span class="comment">//  ----------------- tag</span></span><br><span class="line"></span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;Attr::<span class="title function_ invoke__">Shape</span>(<span class="number">257</span>, <span class="number">258</span>));</span><br><span class="line"><span class="comment">// [1, 0, 1, 1, 2, 1]</span></span><br><span class="line"><span class="comment">//  ^  ^  ^^^^  ^^^^</span></span><br><span class="line"><span class="comment">//  |  |    |     |</span></span><br><span class="line"><span class="comment">//  |  |    |     --- h, 256 + 2</span></span><br><span class="line"><span class="comment">//  |  |    --------- w, 256 + 1</span></span><br><span class="line"><span class="comment">//  |  |------------- padding</span></span><br><span class="line"><span class="comment">//  ----------------- tag</span></span><br></pre></td></tr></table></figure>

<h2 id="Option-lt-P-lt-T-gt-gt"><a href="#Option-lt-P-lt-T-gt-gt" class="headerlink" title="Option&lt;P&lt;T&gt;&gt;"></a><code>Option&lt;P&lt;T&gt;&gt;</code></h2><p>P 是常见的智能指针类型，包括 <code>&amp;</code>&#x2F;<code>&amp;mut</code>&#x2F;<code>Box</code>。这应该是关于 enum layout 优化里最著名的一个例子了。Rust 推荐使用 <code>Option&lt;P&lt;T&gt;&gt;</code> 来处理可空指针，这实现了 <a href="https://en.wikipedia.org/wiki/Void_safety">null safety</a>.</p>
<p><code>Option&lt;T&gt;</code> 在 rust 中被表示为一种 enum：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">enum</span> <span class="title class_">Option</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="literal">None</span>,</span><br><span class="line">    <span class="title function_ invoke__">Some</span>(T),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果不作任何优化的话，显然是存在不必要的 overhead 的，空指针可以完整地表示 <code>None</code> 的语义。由于这种情况太过常见，rustc 不仅针对性地做了优化，而且将其标准化了。</p>
<blockquote>
<p>If T is an FFI-safe non-nullable pointer type, Option<T> is guaranteed to have the same layout and ABI as T and is therefore also FFI-safe. As of this writing, this covers &amp;, &amp;mut, and function pointers, all of which can never be null.</p>
</blockquote>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">p</span> = Box::<span class="title function_ invoke__">new</span>(<span class="number">0u64</span>);</span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;p);</span><br><span class="line"><span class="comment">// [208, 185, 38, 40, 162, 85, 0, 0]</span></span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;<span class="title function_ invoke__">Some</span>(p));</span><br><span class="line"><span class="comment">// [208, 185, 38, 40, 162, 85, 0, 0]</span></span><br></pre></td></tr></table></figure>

<p>一个不算太冷的冷知识是，这种 hack 并不是针对 <code>Option</code> 的，而是针对指针类型的。任何自定义的 enum 满足条件也可以达到相同的效果。</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">MyOption</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="title function_ invoke__">MySome</span>(T),</span><br><span class="line">    MyNone,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> <span class="variable">p</span> = Box::<span class="title function_ invoke__">new</span>(<span class="number">0u64</span>);</span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;MyOption::<span class="title function_ invoke__">MySome</span>(p));</span><br><span class="line"><span class="comment">// [208, 185, 38, 40, 162, 85, 0, 0]</span></span><br><span class="line"><span class="comment">// The address of `p`.</span></span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;MyOption::&lt;<span class="type">Box</span>&lt;<span class="type">u64</span>&gt;&gt;::MyNone);</span><br><span class="line"><span class="comment">// [0, 0, 0, 0, 0, 0, 0, 0]</span></span><br><span class="line"><span class="comment">// Use nullptr to represent `MyNone`.</span></span><br></pre></td></tr></table></figure>

<p><code>Option&lt;P&lt;T&gt;&gt;</code> 可以优化的根本原因是，P 的内存表示下有一个永远非法的值，而相应的 enum 仅需要表示一个额外的值来表达多余的类型。超出这个约束就会导致这个优化失效。</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">MyOption2</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="title function_ invoke__">MySome</span>(T),</span><br><span class="line">    MyNone,</span><br><span class="line">    MyNone2,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> <span class="variable">p</span> = Box::<span class="title function_ invoke__">new</span>(<span class="number">0u64</span>);</span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;MyOption2::<span class="title function_ invoke__">MySome</span>(p));</span><br><span class="line"><span class="comment">// [0, 0, 0, 0, 0, 0, 0, 0, 208, 185, 38, 40, 162, 85, 0, 0]</span></span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;MyOption2::&lt;<span class="type">Box</span>&lt;<span class="type">u64</span>&gt;&gt;::MyNone2);</span><br><span class="line"><span class="comment">// [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</span></span><br></pre></td></tr></table></figure>


<h2 id="bool-Ordering"><a href="#bool-Ordering" class="headerlink" title="bool, Ordering"></a><code>bool</code>, <code>Ordering</code></h2><p>rust 中的 <code>bool</code> 占用一个 byte，且仅有两个合法的值，<code>True</code> 和 <code>False</code>，对应的内存表示为 <code>1u08</code> 和 <code>0u08</code>。我们可以理解为 <code>bool</code> 有 254 个非法值可以供 type tag 挥霍。</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;<span class="title function_ invoke__">Some</span>(<span class="literal">false</span>));</span><br><span class="line"><span class="comment">// [0]</span></span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;<span class="title function_ invoke__">Some</span>(<span class="literal">true</span>));</span><br><span class="line"><span class="comment">// [1]</span></span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;(<span class="literal">None</span> <span class="keyword">as</span> <span class="type">Option</span>&lt;<span class="type">bool</span>&gt;));</span><br><span class="line"><span class="comment">// [2]</span></span><br></pre></td></tr></table></figure>

<p>更进一步地，我们可以更给力一点：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;<span class="title function_ invoke__">Some</span>(<span class="title function_ invoke__">Some</span>(<span class="literal">false</span>)));</span><br><span class="line"><span class="comment">// [0]</span></span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;<span class="title function_ invoke__">Some</span>(<span class="title function_ invoke__">Some</span>(<span class="literal">true</span>)));</span><br><span class="line"><span class="comment">// [1]</span></span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;(<span class="title function_ invoke__">Some</span>(<span class="literal">None</span>) <span class="keyword">as</span> <span class="type">Option</span>&lt;<span class="type">Option</span>&lt;<span class="type">bool</span>&gt;&gt;));</span><br><span class="line"><span class="comment">// [2]</span></span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;(<span class="literal">None</span> <span class="keyword">as</span> <span class="type">Option</span>&lt;<span class="type">Option</span>&lt;<span class="type">bool</span>&gt;&gt;));</span><br><span class="line"><span class="comment">// [3]</span></span><br></pre></td></tr></table></figure>

<p>对应的，Ordering 有三种合法值，同样适用于这个优化。</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;<span class="title function_ invoke__">Some</span>(std::cmp::Ordering::Less));</span><br><span class="line"><span class="comment">// [255]</span></span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;<span class="title function_ invoke__">Some</span>(std::cmp::Ordering::Greater));</span><br><span class="line"><span class="comment">// [1]</span></span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;<span class="title function_ invoke__">Some</span>(std::cmp::Ordering::Equal));</span><br><span class="line"><span class="comment">// [0]</span></span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;(<span class="literal">None</span> <span class="keyword">as</span> <span class="type">Option</span>&lt;std::cmp::Ordering&gt;));</span><br><span class="line"><span class="comment">// [2]</span></span><br></pre></td></tr></table></figure>

<h2 id="Enum"><a href="#Enum" class="headerlink" title="Enum"></a>Enum</h2><p>事实上，编译器并没有对 bool、Ordering 进行特判，任何种类少于 256 的 enum 本身都满足被优化的条件，即 type tag 里会有 (256 - kinds) 个空位。</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">ShapeKind</span> &#123; Square, Circle &#125;</span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;<span class="title function_ invoke__">Some</span>(ShapeKind::Square));</span><br><span class="line"><span class="comment">// [0]</span></span><br><span class="line"></span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;MyOption::<span class="title function_ invoke__">MySome</span>(MyOption::<span class="title function_ invoke__">MySome</span>(<span class="number">1u8</span>)));</span><br><span class="line"><span class="comment">// [0, 1]</span></span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;(MyOption::MyNone <span class="keyword">as</span> MyOption&lt;MyOption&lt;<span class="type">u8</span>&gt;&gt;));</span><br><span class="line"><span class="comment">// [2, 0]</span></span><br><span class="line"><span class="comment">// 尽管 u8 本身没有空位，但是 MyOption 的 type tag 有 254 个空位，因此外层的 MyOption 的 typetag 被优化掉了。</span></span><br></pre></td></tr></table></figure>

<h2 id="Struct、Tuple"><a href="#Struct、Tuple" class="headerlink" title="Struct、Tuple"></a>Struct、Tuple</h2><p>Struct、Tuple 等都属于 Product type。在实现中，往往是将所有字段依次存下来，并做额外的 padding。那么一个理所当然的优化是，如果 struct 的其中一个字段有空位，那么就可以将 enum tag 塞进去。</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">A1</span> (<span class="type">i8</span>, <span class="type">bool</span>);</span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;<span class="title function_ invoke__">Some</span>(<span class="title function_ invoke__">A1</span>(<span class="number">1</span>, <span class="literal">false</span>)));</span><br><span class="line"><span class="comment">// [1, 0]</span></span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;<span class="title function_ invoke__">Some</span>(<span class="title function_ invoke__">A1</span>(<span class="number">1</span>, <span class="literal">true</span>)));</span><br><span class="line"><span class="comment">// [1, 1]</span></span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;(<span class="literal">None</span> <span class="keyword">as</span> <span class="type">Option</span>&lt;A1&gt;));</span><br><span class="line"><span class="comment">// [0, 2]</span></span><br></pre></td></tr></table></figure>

<p>我们再回到文章开头的例子。</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">A</span> (<span class="type">i64</span>, <span class="type">i8</span>);</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">B</span> (<span class="type">i64</span>, <span class="type">i8</span>, <span class="type">bool</span>);</span><br><span class="line"></span><br><span class="line">dbg!(std::mem::size_of::&lt;A&gt;());</span><br><span class="line"><span class="comment">// 16</span></span><br><span class="line">dbg!(std::mem::size_of::&lt;<span class="type">Option</span>&lt;A&gt;&gt;());</span><br><span class="line"><span class="comment">// 24</span></span><br><span class="line">dbg!(std::mem::size_of::&lt;B&gt;());</span><br><span class="line"><span class="comment">// 16</span></span><br><span class="line">dbg!(std::mem::size_of::&lt;<span class="type">Option</span>&lt;B&gt;&gt;());</span><br><span class="line"><span class="comment">// 16</span></span><br><span class="line"></span><br><span class="line"><span class="title function_ invoke__">print_memory</span>(&amp;<span class="title function_ invoke__">Some</span>(<span class="title function_ invoke__">A</span>(<span class="number">1</span>, <span class="number">1</span>)));</span><br><span class="line"><span class="comment">// [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</span></span><br><span class="line"><span class="comment">//  ^  ^^^^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^^^^^^^ ^  ^^^^^^^^^^^^^^^^^^^</span></span><br><span class="line"><span class="comment">//  |           |                      |            |           |</span></span><br><span class="line"><span class="comment">//  |           |                      |            |           ------------ padding</span></span><br><span class="line"><span class="comment">//  |           |                      |            ------------------------ .1</span></span><br><span class="line"><span class="comment">//  |           |                      ------------------------------------- .0</span></span><br><span class="line"><span class="comment">//  |           ------------------------------------------------------------ padding</span></span><br><span class="line"><span class="comment">//  ------------------------------------------------------------------------ tag</span></span><br></pre></td></tr></table></figure>

<p>A 和 B 由于 padding，都需要占用 16 个 byte，而 <code>Option&lt;B&gt;</code> 由于存在一个 bool 字段 <code>.2</code>，tag 被优化进 bool 了，因此也只需要 16 个 byte。反而 <code>Option&lt;A&gt;</code> 实打实地用了 24 个 byte。</p>
<p>一个很容易想到的优化是，使用 padding 中未定义的内存来存储 type tag，然而比较遗憾的是，在 padding 中存储的数据在 copy 等行为下都是未定义行为。这也导致了一个比较滑稽的结果，多存了一个字段，<code>Option</code> 占用的空间反而减少了。</p>
<h2 id="优化自定义结构的可能性"><a href="#优化自定义结构的可能性" class="headerlink" title="优化自定义结构的可能性"></a>优化自定义结构的可能性</h2><p>目前，所有 enum layout 相关的优化都适合由编译器针对特定的类型进行 hack 来实现的，我们无法自己控制我们自定义的 struct 在 enum 中的 layout。为了优化一些常用场景，rust 又提供了 <a href="https://doc.rust-lang.org/std/num/struct.NonZeroI8.html"><code>NonZero*</code></a> 等辅助结构体，用来表示非 0 的整数，与此同时编译器会让 <code>size_of::&lt;Option&lt;NonZeroU8&gt;&gt; == size_of::&lt;u8&gt;</code>。但这只能由标准库 case by case 处理，而真实的需求是非常复杂的，比如有时候我们可能需要 <code>NonMaxU64</code>，或者例如使用了第三方库的 <a href="https://docs.rs/ordered-float/2.10.0/ordered_float/struct.NotNan.html#"><code>Option&lt;ordered_float::NotNan&lt;f64&gt;&gt;</code></a> 就无法被优化。</p>
<p>针对自定义接口的优化需要引入非常复杂的机制，在编译期告诉编译器一个类型非法的内存结构有哪些。我目前感觉一个可能的实现是 const trait + const iterator，给编译器提供潜在的非法值的迭代器。不过目前没有看到相关的 RFC。</p>
<p>这篇文章所有的 example 可以在 <a href="https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=2cecbb4523443229d32a943bea2e48aa">Rust Playground</a> 找到。</p>
]]></content>
      <categories>
        <category>TennyZhuang</category>
      </categories>
      <tags>
        <tag>Rust</tag>
      </tags>
  </entry>
  <entry>
    <title>流处理系统中状态的表示和存储</title>
    <url>/comments/2022/01/15/store-of-streaming-states/</url>
    <content><![CDATA[<p>流处理系统处理的数据往往是没有边界的：数据会一直从数据源输入，用户需要看到 SQL 查询的实时结果。与此同时，流处理系统中的计算节点可能出错、失败，可能根据用户的需求实时扩容、缩容。在这一过程中，系统需要能够高效地将计算的中间状态在节点之间转移，并持久化到外部系统上，从而保证计算的不间断进行。</p>
<p>本文介绍了工业界学术界中流处理系统状态存储的三种方案：存储完整状态 (<a href="https://flink.apache.org/">Flink</a> 等系统)，存储共享状态 (以 <a href="https://github.com/MaterializeInc/materialize">Materialize</a> &#x2F; <a href="https://github.com/TimelyDataflow/differential-dataflow">Differential Dataflow</a> 为例)，存储部分状态 (以 <a href="https://github.com/mit-pdos/noria">Noria (OSDI ‘18)</a> 为例)。这些存储方案各有优势，可以为未来的流处理引擎开发提供一些借鉴意义。</p>
<span id="more"></span>

<h2 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h2><p>假设某个购物系统中有两个表：</p>
<ul>
<li><code>visit(product, user, length)</code> 表示用户查看某产品多少秒。</li>
<li><code>info(product, category)</code> 表示某个产品属于某个分类。</li>
</ul>
<p>现在我们要查询：某个分类下用户查看产品最长的时间是多少。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> <span class="keyword">result</span> <span class="keyword">AS</span></span><br><span class="line">  <span class="keyword">SELECT</span> category,</span><br><span class="line">       <span class="built_in">MAX</span>(length) <span class="keyword">as</span> max_length <span class="keyword">FROM</span></span><br><span class="line">  info <span class="keyword">INNER</span> <span class="keyword">JOIN</span> visit <span class="keyword">ON</span> product</span><br><span class="line">  <span class="keyword">GROUP</span> <span class="keyword">BY</span> category</span><br></pre></td></tr></table></figure>

<p>这个查询中包含两表 Join 和一个聚合操作。后文的讨论都将基于这个查询进行。</p>
<p>假设系统现在的状态是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">info(product, category)</span><br><span class="line">Apple, Fruit</span><br><span class="line">Banana, Fruit</span><br><span class="line">Carrot, Vegetable</span><br><span class="line">Potato, Vegetable</span><br><span class="line"></span><br><span class="line">visit(product, user, length)</span><br><span class="line">Apple, Alice, 10</span><br><span class="line">Apple, Bob, 20</span><br><span class="line">Carrot, Bob, 50</span><br><span class="line">Banana, Alice, 40</span><br><span class="line">Potato, Eve, 60</span><br></pre></td></tr></table></figure>

<p>此时，查询的结果应该是</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">category, max_length</span><br><span class="line">Fruit, 40</span><br><span class="line">Vegetable, 60</span><br></pre></td></tr></table></figure>

<p>代表 Fruit 分类被用户查看最长的时间为 40 秒（对应 Alice 访问 Banana 的时间）；Vegetable 分类被用户查看的最长时间为 60 秒（对应 Eve 访问 Potato 的时间）。</p>
<p>在常见的数据库产品中，系统通常来说会为这个查询生成如下的执行计划（不考虑 optimizer）：</p>
<img src="/comments/2022/01/15/store-of-streaming-states/base-system.png" class="" title="base plan of the query">

<p>流处理系统的执行计划和常见数据库系统的计划没有太多区别。下面将具体介绍各种流处理系统会如何表示和存储计算的中间状态。</p>
<h2 id="Full-State-算子维护自己的完整状态"><a href="#Full-State-算子维护自己的完整状态" class="headerlink" title="Full State - 算子维护自己的完整状态"></a>Full State - 算子维护自己的完整状态</h2><p>诸如 <a href="https://flink.apache.org/">Flink</a> 的流处理系统持久化每个算子的完整状态；与此同时，流计算图上，算子之间传递数据的更新信息。这种存储状态的方法非常符合直觉。前文所述的 SQL，在 Flink 等系统中大致会创建出这个计算图：</p>
<img src="/comments/2022/01/15/store-of-streaming-states/flink-operators.png" class="" title="plan of Flink">

<p>数据源会发出增加一行或是减少一行的消息。经过流算子的处理，这些消息会转变为用户需要的结果。</p>
<h3 id="Join-State-的存储"><a href="#Join-State-的存储" class="headerlink" title="Join State 的存储"></a>Join State 的存储</h3><p>数据源的消息进入系统后，碰到的第一个算子就是 Join。回顾 SQL 查询的 Join 条件: <code>info INNER JOIN visit ON product</code>。Join 算子在收到左侧 <code>info</code> 的消息后，会先将 <code>visit</code> 一侧的 <code>product</code> 相同的行查出来，然后发给下游。之后，将 <code>info</code> 一侧的消息记录在自己的状态中。对于右侧消息的处理也如出一辙。</p>
<p>比如，现在 <code>visit</code> 一侧收到 Eve 对着 Potato 看了 60 秒 <code>+ Potato Eve 60</code> 的消息。假设此时 <code>info</code> 一侧的状态已经有了四条记录。</p>
<img src="/comments/2022/01/15/store-of-streaming-states/flink-state-join.png" class="" title="join state of Flink">

<p>Join 算子会查询 <code>info</code> 一侧 <code>product = Potato</code> 的记录，得到 Potato 是 Vegetable 的结果，之后将 <code>Potato, Vegetable, 60</code> 发给下游。</p>
<p>而后，<code>visit</code> 一侧的状态会加入 <code>Potato -&gt; Eve, 60</code> 的记录，这样一来，如果 <code>info</code> 发生变化，Join 算子也能对应 <code>visit</code> 给下游发送 Join 算子的更新。</p>
<h3 id="Aggregation-State-的存储"><a href="#Aggregation-State-的存储" class="headerlink" title="Aggregation State 的存储"></a>Aggregation State 的存储</h3><p>消息接下来被传递到了 Agg 算子上，Agg 算子需要根据 category 分组，计算每个 category 中 length 的最大值。</p>
<p>一些简单的 Agg 状态 (比如 sum) 只需要记录每一个 group 当前的值就行了。上游发来 insert，就将 sum 加上对应的值；上游发来 delete，就将 sum 减去对应的值。所以，诸如 sum、不带 distinct 的 count 等聚合表达式需要记录的状态非常小。</p>
<p>但对于 max 状态来说，我们就不能只记录最大的那个值了。如果上游发来了一条 delete 消息，max 状态需要把第二大的值作为新的最大值发给下游。如果只记录最大值，删掉最大值以后就没法知道第二大的值是多少。因此，Agg 算子需要存储一个 group 对应的完整数据。比如在我们的例子里，AggMaxState 现在存的数据有：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Fruit -&gt; &#123; 10, 20, 30, 40 &#125;</span><br><span class="line">Vegetable -&gt; &#123; 50 &#125;</span><br></pre></td></tr></table></figure>

<p>上游 Join 算子发来一条插入 <code>Potato, Vegetable, 60</code> 的消息，Agg 算子会更新自己的状态：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Fruit -&gt; &#123; 10, 20, 30, 40 &#125;</span><br><span class="line">Vegetable -&gt; &#123; 50, [60] &#125;</span><br></pre></td></tr></table></figure>

<p>并把 Vegetable 这一组的更新发给下游。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">DELETE Vegetable, 50</span><br><span class="line">INSERT Vegetable, 60</span><br></pre></td></tr></table></figure>

<p>整个过程如下图所示：</p>
<img src="/comments/2022/01/15/store-of-streaming-states/flink-state-agg.png" class="" title="aggregation state of Flink">

<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>存储完整状态的流系统通常来说有这么几个特点：</p>
<ul>
<li>流计算图上单向传递数据变更的消息 (添加&#x2F;删除)。</li>
<li>流算子维护、访问自己的状态；与此同时，在多路 Join 的时候，存储的状态可能重复。后文在介绍共享状态时也会详细介绍这一点。</li>
</ul>
<h2 id="Shared-State-算子之间共享状态"><a href="#Shared-State-算子之间共享状态" class="headerlink" title="Shared State - 算子之间共享状态"></a>Shared State - 算子之间共享状态</h2><p>我们以 <a href="https://github.com/TimelyDataflow/differential-dataflow">Differential Dataflow</a> (<a href="https://github.com/MaterializeInc/materialize">Materialize</a> 下面的计算引擎) 的 Shared Arrangement 为例介绍这种共享状态的实现。下文将使用 DD 简称 Differential Dataflow。</p>
<h3 id="DD-的-Arrange-算子与-Arrangement"><a href="#DD-的-Arrange-算子与-Arrangement" class="headerlink" title="DD 的 Arrange 算子与 Arrangement"></a>DD 的 Arrange 算子与 Arrangement</h3><img src="/comments/2022/01/15/store-of-streaming-states/shared-arrangement.png" class="" title="intro of shared arrangement">

<p>DD 使用 Arrangement 来维护状态。简单来说，Arrangement 是一个支持 MVCC 的 key-value map 数据结构，存储 key 到 (value, time, diff) 的映射。在 Arrangement 上可以：</p>
<ul>
<li>通过 handler 任意查询某个时间点 key-value 的映射关系。</li>
<li>查询某一个 key 在一段时间内的变更情况。</li>
<li>指定查询的水位，后台合并或删除不再使用的历史数据。</li>
</ul>
<p>DD 中大部分算子都是没有状态的，所有的状态都存储在 Arrangement 里。Arrangement 可以使用 Arrange 算子生成，也可以由算子 (比如 Reduce 算子) 自己维护。在 DD 的计算图上，有两种消息传递：</p>
<ul>
<li>数据在某一时刻的变更 <code>(data, time, diff)</code>。这种数据流叫做 Collection。</li>
<li>数据的快照，也就是 Arrangement 的 handler。这种数据流叫做 Arranged。</li>
</ul>
<p>DD 中每个算子的对自己的输入输出也有一定的要求，比如下面几个例子：</p>
<ul>
<li>Map 算子（对应 SQL 的 Projection）输入 Collection 输出 Collection。</li>
<li>JoinCore 算子 (Join 的一个阶段) 输入 Arranged 输出 Collection。</li>
<li>ReduceCore 算子 (Agg 的一个阶段) 输入 Arranged 输出 Arranged。</li>
</ul>
<p>之后我们会详细介绍 DD 中的 JoinCore 和 ReduceCore 算子。</p>
<h3 id="从-Differential-Dataflow-到-Materialize"><a href="#从-Differential-Dataflow-到-Materialize" class="headerlink" title="从 Differential Dataflow 到 Materialize"></a>从 Differential Dataflow 到 Materialize</h3><p>Materialize 会将用户输入的 SQL 查询转换为 DD 的计算图。值得一提的是，<code>join</code>, <code>group by</code> 等 SQL 操作在 DD 中往往不会只对应一个算子。我们顺着消息的流动，看看 Materialize 是如何存储状态的。</p>
<img src="/comments/2022/01/15/store-of-streaming-states/dd-operators.png" class="" title="plan of differential dataflow">

<h3 id="Join-State-的存储-1"><a href="#Join-State-的存储-1" class="headerlink" title="Join State 的存储"></a>Join State 的存储</h3><p>SQL 的 A Join B 操作在 DD 中对应三个算子：两个 <code>Arrange</code> 和一个 <code>JoinCore</code>。Arrange 算子根据 join key 分别持久化状态两个 source 的状态，以 KV 的形式存储在 Arrangement 中。Arrange 算子对输入攒批后，将 TraceHandle 发给下游的 <code>JoinCore</code> 算子。实际的 Join 逻辑在 <code>JoinCore</code> 算子中发生，<code>JoinCore</code> 不存储任何状态。</p>
<img src="/comments/2022/01/15/store-of-streaming-states/dd-state-join.png" class="" title="join state of differential dataflow">

<p>如上图所示，现在 Visit 侧来了一条更新：Eve 对着 Potato 看了 60 秒。<code>JoinCore</code> 算子通过 Trace B 访问到这条更新，并向另一侧的 Trace A 查询 <code>product = Potato</code> 的行，匹配到 <code>Potato</code> 是一种蔬菜，往下游输出 <code>Potato, Vegetable, 60</code> 的更改。</p>
<h3 id="Reduce-状态的存储"><a href="#Reduce-状态的存储" class="headerlink" title="Reduce 状态的存储"></a>Reduce 状态的存储</h3><p>DD 中 SQL Agg 算子对应 Reduce 操作。Reduce 中又包含两个算子：<code>Arrange</code> 和 <code>ReduceCore</code>。<code>Arrange</code> 算子根据 group key 存储输入数据，<code>ReduceCore</code> 算子自己维护一个存储聚合结果的 Arrangement，而后通过 <code>as_collection</code> 操作将聚合结果输出成一个 collection。</p>
<img src="/comments/2022/01/15/store-of-streaming-states/dd-state-agg.png" class="" title="aggregation state of differential dataflow">

<p>Join 的更新来到 Reduce 算子后，先被 Arrange 算子根据 group key 存储在 Arrangement 中。ReduceCore 收到 Trace C 后，将 <code>key = Vegetable</code> 的行全部扫描出来，并求最大值，最后将最大值更新到自己的 Arrangement 中。Trace D 经过 <code>as_collection</code> 操作后，即可输出为数据更新的形式，变成其他算子可以处理的信息。</p>
<h3 id="更方便的算子状态复用"><a href="#更方便的算子状态复用" class="headerlink" title="更方便的算子状态复用"></a>更方便的算子状态复用</h3><p>由于 DD 中存储状态的算子和实际计算的算子是分开的，我们可以利用这个性质做算子状态的复用。</p>
<img src="/comments/2022/01/15/store-of-streaming-states/dd-join-3-way.png" class="" title="3-way join of differential dataflow">

<p>比如用户想要同时查询 <code>A JOIN B</code> 和 <code>B JOIN C</code>，在 DD 中，一种可能的计算图就是生成三个 Arrange 算子和两个 JoinCore 算子。相比于存储完整状态的流处理系统，我们可以避免 B 的状态被存两遍</p>
<p>另一个例子是多路 Join，比如 <code>SELECT * FROM A, B, C WHERE A.x = B.x and A.x = C.x</code>。在这个例子中，如果使用 JoinCore 算子来生成计算图，状态还是有可能重复，一共需要生成 4 个 Arrangement。</p>
<p>Materialize 的 SQL Join 除了被转换为上文所述 DD 的 JoinCore 算子之外，也有可能转换为 Delta Join。如图所示，我们只需要分别生成 A, B, C 的 3 个 Arrangement，然后使用 lookup 算子查询 A 的修改在 B C 中对应的行（其他两个表的修改亦然），最后做一个 union，即可得到 Join 的结果。Delta Join 可以充分利用已有的 Arrangement 进行计算，大大减小 Join 所需的状态存储数。</p>
<h3 id="远程访问状态的开销"><a href="#远程访问状态的开销" class="headerlink" title="远程访问状态的开销"></a>远程访问状态的开销</h3><p>在流系统中，计算中间产生的数据往往无法全部放在一个结点上；与此同时，同一个执行计划中的节点，也会有很多并行度。比如下面这个两表 Join 的例子。两个表 A、B 的 Arrangement 可能分别在两个结点上产生 (Node 1, 2)，然后同时用两个结点分别对其中一部分数据做 Join。</p>
<img src="/comments/2022/01/15/store-of-streaming-states/dd-remote-shuffle.png" class="" title="remote shuffle of differential dataflow">

<p>在这个情况下，DD 中势必会发生远程访问 Arrangement 的问题。由于算子完全没有内部状态，JoinCore 每处理一行都需要一次远程访问，查找 join key 对应的数据。总的来说，Arrange 和计算放在两个结点上会大大增加计算的延迟，放在一个结点上又无法充分利用分布式系统的资源，这是一个比较矛盾的地方。</p>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>在共享状态的流处理系统中，算子的计算逻辑和存储逻辑被拆分到多个算子中。因此，不同的计算任务可以共享同一个存储，从而减少存储状态的数量。如果要实现共享状态的流处理系统，一般会有这样的特点：</p>
<ul>
<li>流计算图上传递的不仅仅是数据的变更，可能还会包括状态的共享信息（比如 DD 的 Trace Handle）。</li>
<li>流算子访问状态会有一定的开销；但相对而言存储完整状态的流计算系统而言，整个流计算过程中由于状态复用，存储的状态数量更小。</li>
</ul>
<h2 id="Partial-State-算子只存储部分信息"><a href="#Partial-State-算子只存储部分信息" class="headerlink" title="Partial State - 算子只存储部分信息"></a>Partial State - 算子只存储部分信息</h2><p>在 <a href="https://github.com/mit-pdos/noria">Noria (OSDI ‘18)</a> 这一系统中，计算不会在数据源更新信息时触发，流处理算子并不会保存完整的信息。</p>
<p>比如，如果用户在之前创建的视图上执行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SELECT * FROM result WHERE category = &quot;Vegetable&quot;</span><br></pre></td></tr></table></figure>

<p>执行这条 SQL 的时候，才会触发流系统的计算。计算过程中，也只计算 <code>category = &quot;Vegetable&quot;</code> 相关的数据，保存相关的状态。下面将以这条查询为例，说明 Noria 的计算方式与状态存储。</p>
<h3 id="Upquery"><a href="#Upquery" class="headerlink" title="Upquery"></a>Upquery</h3><p>Noria 的各个算子仅存储部分数据。用户的查询可能直接击中这个部分状态的缓存，也有可能需要回溯到上游查询。假设现在所有算子的状态都为空，Noria 需要通过 upquery 来递归查询上游算子的状态，从而得到正确的结果。</p>
<img src="/comments/2022/01/15/store-of-streaming-states/noria-upquery.png" class="" title="upquery of Noria">

<p>用户向流计算引擎查询 <code>category = &quot;Vegetable&quot;</code> 的最大值。Agg 算子为了计算出它的结果，需要知道所有 category 为蔬菜的记录。于是，Agg 算子将这个 upquery 转发到上游 Join 算子。</p>
<p>Join 算子要得到蔬菜对应的所有信息，需要向两个上游表分别查询情况。category 属于 Info 表的列，因此，Join 算子将这条 upquery 转发给 Info 表。</p>
<h3 id="Join-算子的实现"><a href="#Join-算子的实现" class="headerlink" title="Join 算子的实现"></a>Join 算子的实现</h3><img src="/comments/2022/01/15/store-of-streaming-states/noria-join-left.png" class="" title="join implementation of Noria - the left side">

<p>Info table 返回蔬菜分类下的所有产品后，Join 算子会再发一个 upquery 给另一边 Visit table，查询萝卜、土豆对应的浏览记录。</p>
<img src="/comments/2022/01/15/store-of-streaming-states/noria-join-right.png" class="" title="join implementation of Noria - the right side">

<p>Visit table 返回对应记录后，Join 算子就可以根据两次 Upquery 的输出计算出 Join 结果了。</p>
<p>在 Noria 中，Join 算子无需保存任何实际状态，仅需要记录正在进行的 upquery 即可。</p>
<h3 id="Agg-算子的实现"><a href="#Agg-算子的实现" class="headerlink" title="Agg 算子的实现"></a>Agg 算子的实现</h3><img src="/comments/2022/01/15/store-of-streaming-states/noria-agg.png" class="" title="aggregation implementation of Noria">

<p>数据来到 Agg 算子后，Noria 将直接计算出最大值，并将最大值存储在算子的状态中。在前文所述的系统里，Agg 算子的状态需要保存完整的数据（水果的所有浏览记录、蔬菜的所有浏览记录）。Noria 只需要缓存用户请求的状态，因此在这个请求中只要记录蔬菜的记录。与此同时，如果上游发生了删除操作，Noria 可以直接将蔬菜对应的行删除，以便之后重新计算最大值。因此，在存储部分状态的系统中，也无需通过记录所有值的方法回推第二大的值——直接清空缓存就行了。</p>
<h3 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h3><p>存储部分状态的流处理系统通过 upquery 的方式实时响应用户的请求，在本文所述的实现中，所需要存储的状态数最少。它一般有以下特点：</p>
<ul>
<li>计算图的数据流向是双向的——既可以从上游到下游输出数据，也可以从下游到上游发 upquery。</li>
<li>由于需要递归 upquery，计算的延迟可能比其他状态存储方式略微大一点。</li>
<li>数据一致性比较难实现。本文所述的其他存储方法都可以比较简单地实现最终一致；但对于存储部分状态的系统来说，需要比较小心地处理更新和 upquery 返回结果同时在流上传递的问题，对于每个算子都要仔细证明实现的正确性。</li>
<li>DDL &#x2F; Recovery 非常快。由于算子里面的信息都是按需计算的，如果用户对 View 进行增删列的操作，或是做迁移，都可以直接清空缓存分配新节点，无需代价较高的状态恢复。</li>
</ul>
<p>最后对比一下所有的状态存储方式所对应的流处理系统特征：</p>
<img src="/comments/2022/01/15/store-of-streaming-states/state-compare.png" class="" title="comparison of streaming state stores">

<ul>
<li>存储完整状态 (以 Flink 为例)：流上传递数据。</li>
<li>共享状态存储 (以 Materialize &#x2F; DD 为例)：流上传递数据和 snapshot。</li>
<li>存储部分状态 (以 Noria 为例)：流上传递数据，流上双向都有消息。</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://flink.apache.org/">Apache Flink</a></li>
<li><a href="https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/dev/table/sql/gettingstarted/">Flink SQL</a></li>
<li><a href="https://github.com/MaterializeInc/materialize">Materialize</a></li>
<li><a href="https://materialize.com/joins-in-materialize/">Joins in Materialize</a></li>
<li><a href="https://materialize.com/maintaining-joins-using-few-resources/">Maintaining Joins using Few Resources</a></li>
<li><a href="https://github.com/TimelyDataflow/differential-dataflow">differential-dataflow</a></li>
<li><a href="https://github.com/mit-pdos/noria">Noria</a></li>
</ul>
<p>写这篇文章时，我也大量阅读了 Materialize, Differential Dataflow 和 Noria 的源代码。如果有具体实现上的问题，也欢迎交流。</p>
]]></content>
      <categories>
        <category>skyzh</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>流式计算</tag>
        <tag>存储系统</tag>
      </tags>
  </entry>
</search>
